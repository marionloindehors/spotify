{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048fa817",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Project Description \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89222d7a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **The objective is to create a model that predicts the popularity of a song based on its characteristics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf15564",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Details on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd35614",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Dataset contains a list of songs with the following characteristics:\n",
    "\n",
    "**acousticness**: whether the track is acoustic  \n",
    "\n",
    "**danceability**: describes how suitable a track is for dancing  \n",
    "\n",
    "**duration_ms**: duration of the track in milliseconds  \n",
    "\n",
    "**energy**: represents a perceptual measure of intensity and activity  \n",
    "\n",
    "**explicit**: whether the track has explicit lyrics  \n",
    "\n",
    "**id**: id for the track  \n",
    "\n",
    "**instrumentalness**: predicts whether a track contains no vocals  \n",
    "\n",
    "**key**: the key the track is in  \n",
    "\n",
    "**liveness**: detects the presence of an audience in the recording  \n",
    "\n",
    "**loudness**: the overall loudness of a track in decibels  \n",
    "\n",
    "**mode**: modality of a track  \n",
    "\n",
    "**name**: name of the track  \n",
    "\n",
    "**popularity**: popularity of the track  \n",
    "\n",
    "**release_date**: release date  \n",
    "\n",
    "**speechiness**: detects the presence of spoken words in a track  \n",
    "\n",
    "**tempo**: overall estimated tempo of a track in beats per minute  \n",
    "\n",
    "**valence**: describes the musical positiveness conveyed by a track  \n",
    "\n",
    "**artist**: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4bd1e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcd067",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **Load and clean the data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6e2738",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55733d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(f'df shape : {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180363d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Clean the data : make sure that no duplicates nor missing values remain in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b8dc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Counting duplicates\n",
    "print(f'duplicates : {df.duplicated().sum()}')\n",
    "\n",
    "# Counting the number of NaN for each column\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af74658",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates and NaN from df \n",
    "df = df.drop_duplicates().dropna()\n",
    "\n",
    "# Check duplicates and NaN are well droped\n",
    "print(f'duplicates : {df.duplicated().sum()}')\n",
    "print(f'duplicates : {df.isnull().sum()}')\n",
    "\n",
    "#Check new shape \n",
    "print(f'df new shape : {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692fb03",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda4113",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **Baseline and evaluation of a basic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a51e7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Scoring metric : Negative RMSE\n",
    "\n",
    "- strongly penalize largest errors relatively to smaller ones  \n",
    "- measure errors in the same unit as the target `popularity`  \n",
    "- the greater, the better (metric_good_model > metric_bad_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de223947",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scoring = 'neg_root_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5e372",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08f7e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_simple = df.select_dtypes(include=['int64', 'float64'])\n",
    "y = df['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa567b8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb871d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute mean squared error\n",
    "mse = np.mean((y - y.mean())**2)\n",
    "\n",
    "# Compute the negative RMSE \n",
    "baseline_score = -np.sqrt(mse)\n",
    "print(f'Baseline score is {baseline_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2282f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Split data and Evaluate on basic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89025012",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_simple, X_test_simple, y_train, y_test = train_test_split(X_simple, y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'X_train_simple shape : {X_train_simple.shape}')\n",
    "print(f'y_train : {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec3134",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create function for neg rmse\n",
    "def neg_rmse(y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return -rmse\n",
    "\n",
    "# Create scorer \n",
    "score = make_scorer(neg_rmse, greater_is_better=True)\n",
    "\n",
    "# Instanciate model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train model on train set\n",
    "model.fit(X_train_simple, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_simple)\n",
    "\n",
    "# Evaluate with neg rmse\n",
    "score_simple_holdout = score(model, X_test_simple, y_test)\n",
    "\n",
    "print(f'Score on basic Linear Regression : {score_simple_holdout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf709a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Cross-Validation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe014a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_result = cross_val_score(model_simple, X_train_simple, y_train, cv=5, scoring=scoring)\n",
    "\n",
    "score_simple_cv_mean = scores_result.mean()\n",
    "score_simple_cv_std = scores_result.std()\n",
    "\n",
    "print(f\"Mean score : {score_simple_cv_mean}\")\n",
    "print(f\"Standard deviation : {score_simple_cv_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3d1fc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43286df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ Improving performance using the feature release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b94e45",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert release_date to datetime\n",
    "year_col = pd.to_datetime(df['release_date'])\n",
    "\n",
    "# Extract year\n",
    "year_col = year_col.dt.year\n",
    "\n",
    "# Join year_col to X_Simple into new DF X_engineered\n",
    "X_engineered = X_simple.join(year_col)\n",
    "X_engineered = X_engineered.drop(columns='release_date')\n",
    "\n",
    "print(f'X_engineered shape : {X_engineered.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658614fa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Retrain a basic Linear Regression to check the impact of the new feature on the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75adde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model on train set\n",
    "model.fit(X_engineered, y)\n",
    "\n",
    "# Cross Validate\n",
    "scores_result = cross_val_score(model, X_engineered, y, cv=5, scoring=scoring)\n",
    "score_engineered = scores_result.mean()\n",
    "\n",
    "print(f'New score : {score_engineered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a285d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82264b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Using a KMeans to assign each track to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b13f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "n = 5\n",
    "\n",
    "# Instanciate model & Fit \n",
    "km = KMeans(n_clusters=n)\n",
    "kmeans = km.fit(X_simple)\n",
    "\n",
    "# Get cluster predictions on X_simple\n",
    "cluster_pred = kmeans.predict(X_simple)\n",
    "cluster_pred\n",
    "\n",
    "# New column of X_engineered with clusters\n",
    "X_engineered['clusters'] = cluster_pred\n",
    "\n",
    "# Check\n",
    "X_engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8aebbe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Check the impact of the new clusters feature on the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b37013",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Re-train model on X_engineered\n",
    "model.fit(X_engineered, y)\n",
    "\n",
    "# Cross Validate\n",
    "scores_result_c = cross_val_score(model, X_engineered, y, cv=5, scoring=scoring)\n",
    "score_clusters = scores_result_c.mean()\n",
    "\n",
    "print(f'New score : {score_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89342a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dd510",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **Constructing a preprocessing pipeline for the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76213c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This help visualize pipelines\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460b099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reloading a clean new dataset\n",
    "X = df.drop(columns='popularity')\n",
    "y = df['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e86e96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create new df with only object-type columns\n",
    "object_columns = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Print the object-type columns\n",
    "print(f'Object-type columns : {object_columns.columns})\n",
    "\n",
    "#Check their number of unique values\n",
    "print(f'Unique values in id column : {len(object_columns.id.unique())}')\n",
    "print(f'Unique values in name column : {len(object_columns.name.unique())}')\n",
    "print(f'Unique values in realease_date column : {len(object_columns.release_date.unique())}')\n",
    "print(f'Unique values in artist column : {len(object_columns.artist.unique())}')\n",
    "      \n",
    "print('No need to One-Hot-Encode those columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb913d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Custom Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef4654",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Creating a custom transformer to extract the year from release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68dbc97",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def extract_year(x):\n",
    "    x = pd.to_datetime(x)\n",
    "    return x.dt.year\n",
    "\n",
    "transformer_year_2 = FunctionTransformer(extract_year, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b86571",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def release_date(data):\n",
    "    tab=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        tab.append(int(data.iloc[i]['release_date'][0:4]))\n",
    "    return pd.DataFrame(tab)\n",
    "\n",
    "transformer_year = FunctionTransformer(release_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1493d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Creating a pipeline_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299861b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipeline_year = Pipeline([\n",
    "    ('transformer_year', transformer_year),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b153d4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Creating a pipeline_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c542b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Provided : Custom transformer to extract a cluster id for each observation\n",
    "def process_clusters(clusters):\n",
    "    return np.argmin(clusters, axis=1).reshape((-1, 1))\n",
    "\n",
    "transformer_clusters = FunctionTransformer(process_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8d4b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "pipeline_clusters = Pipeline([\n",
    "    ('kmeans', KMeans(n_clusters=n)),\n",
    "    ('transformer_cluster', transformer_clusters),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pipeline_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5c51e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Creating a pipeline_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2f6f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Provided : Custom transformer custom Transformer Class below\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Compute, as a new feature the artist's popularity\n",
    "    Do so by computing the mean popularity of all songs from the artist\n",
    "    Notice that the popularity is computed on the train only to avoid leakage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "        self.artist_popularity = y.groupby(X.artist).agg(\"mean\")\n",
    "        self.artist_popularity.name = \"artist_popularity\"\n",
    "\n",
    "        # process mean popularity\n",
    "        self.mean_popularity = y.mean()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "\n",
    "        # inject artist popularity\n",
    "        X_copy = X.merge(self.artist_popularity, how=\"left\", left_on=\"artist\", right_index=True)\n",
    "\n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "        X_copy.replace(np.nan, self.mean_popularity, inplace=True)\n",
    "\n",
    "        return X_copy[[\"artist_popularity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c2401",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instanciate and fit Class\n",
    "artist_popularity = ArtistPopularityTransformer()\n",
    "artist_popularity = artist_popularity.fit(X,y)\n",
    "\n",
    "# Make pipeline\n",
    "pipeline_artist = Pipeline([\n",
    "    ('transformer', ArtistPopularityTransformer()),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a0d7b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Preprocessing Pipeline with all Column Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744a89b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Select only numeric features\n",
    "numeric_features = ['acousticness','danceability',\n",
    " 'duration_ms',\n",
    " 'energy',\n",
    " 'explicit',\n",
    " 'instrumentalness',\n",
    " 'key',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'tempo',\n",
    " 'valence']\n",
    "\n",
    "# Create preprocessor Pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_features', pipeline_clusters, numeric_features),\n",
    "    ('scaler_num', MinMaxScaler(), numeric_features),\n",
    "    ('release_date', pipeline_year, ['release_date']),\n",
    "    ('artist', pipeline_artist, ['artist'])],remainder='drop')\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7c36a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Use pipeline to transform X to X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd4dd2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit Preprocessor \n",
    "preprocessor.fit(X,y)\n",
    "\n",
    "# Transform X\n",
    "X_transformed = preprocessor.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9963d1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92982f01",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **Select the model that yields the best performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74772521",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33534b84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Construct Pipeline with processor + model\n",
    "pipe_linear = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "# Cross-validate Pipeline\n",
    "score_linear = cross_val_score(pipe_linear, X, y, cv=5, scoring=scoring).mean()\n",
    "\n",
    "print(f'Ridge model score : {score_linear}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1660925",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c87c69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instanciate model\n",
    "model = RandomForestRegressor(max_depth=5,min_samples_leaf=5)\n",
    "\n",
    "# Construct Pipeline with processor + model\n",
    "pipe_ensemble = make_pipeline(preprocessor, model)\n",
    "\n",
    "# Cross-validate \n",
    "score_ensemble = cross_val_score(pipe_ensemble, X, y, cv=5, scoring=scoring).mean()\n",
    "\n",
    "print(f'RandomForestRegressor model score : {score_ensemble}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c0740",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Trying another model\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instanciate model\n",
    "model_gbr = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "# Construct Pipeline with processor + model\n",
    "pipe_gb = make_pipeline(preprocessor, model_gbr)\n",
    "\n",
    "# Cross-validate \n",
    "score = cross_val_score(pipe_gb, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "print(f'GBR model score : {score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d32d80",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fine-Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17f741",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üéØ **Fine-tuning the best model to achieve the highest possible score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfcf1b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üìù Cross-validating grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fe2f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a dictionary with the hyperparameters to search\n",
    "grid = {\n",
    "    'model__n_estimators': [10, 50, 100],\n",
    "    'model__max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Create the cross-validated grid search\n",
    "search = GridSearchCV(pipe_ensemble, grid, scoring=scoring, cv=5)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af50100",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print the best score and best parameters\n",
    "print(f'Best score: {search.best_score_}')\n",
    "print(f'Best parameters: {search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caca7b2",
   "metadata": {},
   "source": [
    "## Recommendations and Continuous Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbccdc",
   "metadata": {},
   "source": [
    "üéØ **Transform a regression task into a classification task**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1056a",
   "metadata": {},
   "source": [
    "üìù Creating a new target y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15934e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of y\n",
    "median = y.median()\n",
    "\n",
    "# Create y_cat using the median of y\n",
    "y_cat = y.apply(lambda x: 1 if x >= median else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b355536",
   "metadata": {},
   "source": [
    "üìù Cross validating a classification with accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline with preprocessor and model\n",
    "pipe_cat = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Cross validate the pipeline with 5 folds\n",
    "scores = cross_val_score(pipe_cat, X, y_cat, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate the mean of the scores\n",
    "score_cat = scores.mean()\n",
    "\n",
    "print(f'Accuracy score for LogReg : {score_cat}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
